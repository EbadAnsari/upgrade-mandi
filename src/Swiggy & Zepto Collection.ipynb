{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdacbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from math import floor\n",
    "from os.path import join\n",
    "from pprint import pprint\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a95f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nameExtracter(rightNamesList: List[str], wrongName: str) -> str:\n",
    "    chances = [0] * len(rightNamesList)\n",
    "\n",
    "    counterOriginal = Counter(wrongName.lower())\n",
    "    for i, rightName in enumerate(rightNamesList):\n",
    "        counterLocation = Counter(rightName.lower())\n",
    "        chances[i] = (\n",
    "            sum((counterOriginal & counterLocation).values())\n",
    "            * 2\n",
    "            / (sum(counterOriginal.values()) + sum(counterLocation.values()))\n",
    "        )\n",
    "    return rightNamesList[chances.index(max(chances))]\n",
    "\n",
    "\n",
    "prev = 0\n",
    "\n",
    "\n",
    "def pretty(label: str, completed: float, total: int, length: int = 30) -> None:\n",
    "    global prev\n",
    "    print(\n",
    "        \" \" * prev * 2\n",
    "        + f\"\\r{label} [\"\n",
    "        + \"=\" * int(completed / total * length)\n",
    "        + \"-\" * int((total - completed) / total * length)\n",
    "        + f\"] {int(completed / total * 100)}%\",\n",
    "        end=\"\",\n",
    "    )\n",
    "    prev = length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa226c86",
   "metadata": {},
   "source": [
    "##### Hard Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fe8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_FOLDER_PATH = \"./../data/raw\"\n",
    "CLEANED_FOLDER_PATH = \"./../data/cleaned\"\n",
    "\n",
    "domains = [\"Swiggy\", \"Zepto\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79d087",
   "metadata": {},
   "source": [
    "##### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d057ba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 domains with 4 files.\n",
      "{'Swiggy': ['./../data/raw\\\\Swiggy 01-01-2025 - 15-04-2025.xlsx',\n",
      "            './../data/raw\\\\Swiggy 09-04-2025 - 22-06-2025.xlsx',\n",
      "            './../data/raw\\\\Swiggy 22-06-2025 - 10-07-2025.xlsx'],\n",
      " 'Zepto': ['./../data/raw\\\\Zepto 10-07-2025 - 20-06-2025.xlsx']}\n"
     ]
    }
   ],
   "source": [
    "excelBooks: dict[str, List[dict[str, pd.DataFrame]]] = {\n",
    "    domain: [\n",
    "        pd.read_excel(path, sheet_name=None)\n",
    "        for path in glob(join(RAW_FOLDER_PATH, \"*.xlsx\"))\n",
    "        if domain == nameExtracter(domains, path)\n",
    "    ]\n",
    "    for domain in domains\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Found {len(excelBooks)} domains with {sum([len(excelBooks[domain]) for domain in excelBooks])} files.\"\n",
    ")\n",
    "\n",
    "pprint(\n",
    "    {\n",
    "        domain: [\n",
    "            path\n",
    "            for path in glob(join(RAW_FOLDER_PATH, \"*.xlsx\"))\n",
    "            if domain == nameExtracter(domains, path)\n",
    "        ]\n",
    "        for domain in domains\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac19e64",
   "metadata": {},
   "source": [
    "##### Extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e7d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract:\n",
    "    def __checkColumnName(self, col: pd.Series):\n",
    "        return (\n",
    "            col.astype(str)\n",
    "            .apply(\n",
    "                lambda string: \" \".join(\n",
    "                    list(\n",
    "                        filter(\n",
    "                            lambda x: not x.isspace() and x,\n",
    "                            string.lower().replace(\"\\n\", \"\").split(\" \"),\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            .isin(list(map(lambda x: x.lower(), self.columns)))\n",
    "            .any()\n",
    "        )\n",
    "\n",
    "    def __extractTable(self, row: pd.Series) -> bool:\n",
    "        return str(row[self.columns[0]]).isnumeric()\n",
    "\n",
    "    def __extractDateLocation(self, rawString: str) -> Tuple[datetime, str] | False:\n",
    "        datePattern = \"^(\\d){1,2}[-/](\\d){1,2}[-/](\\d){4}\"\n",
    "        dateMached = re.match(datePattern, rawString)\n",
    "\n",
    "        if dateMached:\n",
    "            dateFormat = \"%d-%m-%Y\"\n",
    "            date = datetime.strptime(\n",
    "                re.sub(r\"[-/]\", \"-\", dateMached.group(0)), dateFormat\n",
    "            ).strftime(\"%m-%d-%Y\")\n",
    "\n",
    "            # print(self.locations.keys())\n",
    "            area = nameExtracter(\n",
    "                list(self.locations.keys()),\n",
    "                rawString,\n",
    "            ).title()\n",
    "\n",
    "            return (date, area)\n",
    "        return (False, False)\n",
    "\n",
    "    # dict[str, dict[str, str]]\n",
    "    def __init__(self, columns: List[str], locations: List[str], vendorName: str):\n",
    "        self.columns: List[str] = columns\n",
    "        self.locations = locations\n",
    "        self.vendorName = vendorName\n",
    "\n",
    "        self.locationParsed = {x: [] for x in self.locations}\n",
    "        self.processedDataFrame: pd.DataFrame = pd.DataFrame(columns=self.columns)\n",
    "\n",
    "    def extractDataFrame(self, sheetName: str, sheetData: pd.DataFrame):\n",
    "        # sheetData.columns = self.columns[:-2]\n",
    "        date, location = self.__extractDateLocation(sheetName)\n",
    "        if date == False:\n",
    "            print(sheetName)\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        sheetData = sheetData[\n",
    "            sheetData.columns[sheetData.apply(self.__checkColumnName, axis=0)]\n",
    "        ].copy()\n",
    "\n",
    "        sheetData.columns = self.columns\n",
    "        sheetData = sheetData[sheetData.apply(self.__extractTable, axis=1)].copy()\n",
    "\n",
    "        invoiceVersion = 1\n",
    "        numbers = re.findall(r\"\\d+(?:\\.\\d+)?\", sheetName[11:])\n",
    "        if numbers:\n",
    "            invoiceVersion = int(numbers[0])\n",
    "\n",
    "        sheetData[\"Date\"] = date\n",
    "        sheetData[\"Location\"] = location\n",
    "        self.locationParsed[location].append(sheetName)\n",
    "        sheetData[\"Invoice Version\"] = invoiceVersion\n",
    "        sheetData[\"Retailer\"] = self.locations[location][\"retailer\"]\n",
    "        sheetData[\"Vendor Name\"] = self.vendorName\n",
    "        sheetData[\"Shipping Address\"] = self.locations[location][\"shipping-address\"]\n",
    "        sheetData[\"Invoice Version\"].astype(int)\n",
    "\n",
    "        return sheetData\n",
    "\n",
    "    def add(self, dataFrame: pd.DataFrame):\n",
    "        dataFrame = dataFrame.dropna(how=\"all\", axis=1)\n",
    "        if not dataFrame.empty:\n",
    "            self.processedDataFrame = pd.concat(\n",
    "                [self.processedDataFrame, dataFrame], ignore_index=True\n",
    "            )\n",
    "\n",
    "    def save(self, fileName):\n",
    "        self.processedDataFrame.to_csv(fileName, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59503ac9",
   "metadata": {},
   "source": [
    "##### Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a58b864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swiggy [==============================] 100%                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "Swiggy [==============================] 100%                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "Swiggy [==============================] 100%                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "Processed Swiggy data.\n",
      "\n",
      "Zepto [==============================] 100%                                                                                                                                                                                                                                                                                                         \n",
      "Processed Zepto data.\n",
      "\n",
      "The following sheets are not parsed: \n",
      "{'Swiggy': [], 'Zepto': []}\n"
     ]
    }
   ],
   "source": [
    "inputParameters = {\n",
    "    \"Swiggy\": {\n",
    "        \"columns\": [\n",
    "            \"Article Code\",\n",
    "            \"Item Description\",\n",
    "            \"UoM\",\n",
    "            \"Dispatched Qty\",\n",
    "            \"Rate\",\n",
    "            \"Total Amount\",\n",
    "        ],\n",
    "        \"locations\": {\n",
    "            \"Nandanvan\": {\n",
    "                \"shipping-address\": 'Vinayak Tower\", Lower Ground Floor, Survey No.212 Gurudev Nagar Main Road, New Nanadanvan',\n",
    "                \"retailer\": \"Swinsta\",\n",
    "            },\n",
    "            \"Dharampeth\": {\n",
    "                \"shipping-address\": \"Plot No. 151, CTS No. 135Puja Sabhagrah, Ravi Nagar Square, Ram Nagar\",\n",
    "                \"retailer\": \"Swinsta\",\n",
    "            },\n",
    "            \"Mahal\": {\n",
    "                \"shipping-address\": \"Unit no - G-1, Plot no.58, sardar patel timber Dhantoli, NAGPUR- 440027\",\n",
    "                \"retailer\": \"Rajidi\",\n",
    "            },\n",
    "            \"Ayodhya Nagar\": {\n",
    "                \"shipping-address\": \"Gadewar Lawns Plot No.31,32,33,36,37And 38,K. H. No, 72/2, Situated At Gadewar Lawn , Shri Ram Wadi\",\n",
    "                \"retailer\": \"Rajidi\",\n",
    "            },\n",
    "            \"Sai Mandir\": {\n",
    "                \"shipping-address\": \"Khasra No 18/2, city Survey No.718, House No. 781/B, Situated at Village Ajni\",\n",
    "                \"retailer\": \"Swinsta\",\n",
    "            },\n",
    "            \"Manish Nagar\": {\n",
    "                \"shipping-address\": 'Ground floor \"Jayanti Mansion III\"Manish nagar  Nagpur Maharashtra',\n",
    "                \"retailer\": \"Rajidi\",\n",
    "            },\n",
    "            \"Byramji\": {\n",
    "                \"shipping-address\": 'Unit nos - 59 to 71 Lower Ground FloorGinger Square\" City Survey No - 1049',\n",
    "                \"retailer\": \"Rajidi\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"Zepto\": {\n",
    "        \"columns\": [\n",
    "            \"No\",\n",
    "            \"Article Name\",\n",
    "            \"UoM\",\n",
    "            \"Invoice Qty.\",\n",
    "            \"Rate\",\n",
    "            \"Amount\",\n",
    "        ],\n",
    "        \"locations\": {\n",
    "            \"Gokulpeth\": {\"shipping-address\": \"\", \"retailer\": \"Dorgheria\"},\n",
    "            \"Mahada\": {\"shipping-address\": \"\", \"retailer\": \"Dorgheria\"},\n",
    "            \"Khamla\": {\"shipping-address\": \"\", \"retailer\": \"Dorgheria\"},\n",
    "            \"Garoba Maidan\": {\"shipping-address\": \"\", \"retailer\": \"Dorgheria\"},\n",
    "            \"Raghuji Nagar\": {\"shipping-address\": \"\", \"retailer\": \"Dorgheria\"},\n",
    "            \"Zingabai Takli\": {\"shipping-address\": \"\", \"retailer\": \"Dorgheria\"},\n",
    "            \"Bhupesh Nagar\": {\"shipping-address\": \"\", \"retailer\": \"Dorgheria\"},\n",
    "            \"Besa\": {\"shipping-address\": \"\", \"retailer\": \"Dorgheria\"},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "extractedDomains: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "errorSheets: dict[str, List[str]] = {domain: [] for domain in domains}\n",
    "\n",
    "for domain in domains:\n",
    "    # if domain == \"Swiggy\":\n",
    "    #     continue\n",
    "    extract = Extract(\n",
    "        inputParameters[domain][\"columns\"],\n",
    "        inputParameters[domain][\"locations\"],\n",
    "        \"Upgrade Mandi\",\n",
    "    )\n",
    "    for excelBook in excelBooks[domain]:\n",
    "        count = 0\n",
    "        for sheetName, sheetData in excelBook.items():\n",
    "            if sheetData.empty:\n",
    "                errorSheets.append(sheetName)\n",
    "                continue\n",
    "            # print(sheetName)\n",
    "\n",
    "            try:\n",
    "                df = extract.extractDataFrame(sheetName, sheetData)\n",
    "                # pass\n",
    "                if not df.empty:\n",
    "                    extract.add(df)\n",
    "                else:\n",
    "                    errorSheets.append(sheetName)\n",
    "            except:\n",
    "                # print(sheetData, sheetData.columns.__len__())\n",
    "                # print(f\"Error processing sheet: {sheetName}\")\n",
    "                errorSheets[domain].append(sheetName)\n",
    "                break\n",
    "            count += 1\n",
    "            pretty(domain, count, len(excelBook), 30)\n",
    "        print()\n",
    "    print(f\"Processed {domain} data.\\n\")\n",
    "\n",
    "    extractedDomains[domain] = extract\n",
    "\n",
    "print(\"The following sheets are not parsed: \")\n",
    "pprint(errorSheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99279c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in extractedDomains:\n",
    "    extractedDomains[domain].save(join(CLEANED_FOLDER_PATH, f\"{domain}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f5bb53",
   "metadata": {},
   "source": [
    "##### Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51ea0bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "loc",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d345ba53-0f27-472f-aef7-2a3199074944",
       "rows": [
        [
         "3",
         "08-04-2025 DHARAMPETH"
        ],
        [
         "4",
         "08-04-2025 MAHAL"
        ],
        [
         "9",
         "07-04-2025 DHARAMPETH"
        ],
        [
         "10",
         "07-04-2025 MAHAL"
        ],
        [
         "20",
         "06-04-2025 MAHAL"
        ],
        [
         "21",
         "06-04-2025 DHARAMPETH"
        ],
        [
         "22",
         "04-04-2025 MAHAL"
        ],
        [
         "23",
         "04-04-2025 DHARAMPETH"
        ],
        [
         "30",
         "03-04-2025 MAHAL"
        ],
        [
         "35",
         "03-04-2025 DHARAMPETH"
        ],
        [
         "36",
         "02-04-2025 MAHAL"
        ],
        [
         "41",
         "02-04-2025 DHARAMPETH"
        ],
        [
         "45",
         "01-04-2025 MAHAL"
        ],
        [
         "49",
         "01-04-2025 DHARAMPETH"
        ],
        [
         "52",
         "31-03-2025 DHARAMPETH"
        ],
        [
         "55",
         "31-03-2025 MAHAL"
        ],
        [
         "62",
         "30-03-2025 MAHAL"
        ],
        [
         "64",
         "30-03-2025 DHARAMPETH"
        ],
        [
         "66",
         "28-03-2025 DHARAMPETH"
        ],
        [
         "68",
         "28-03-2025 MAHAL"
        ],
        [
         "75",
         "27-03-2025 DHARAMPETH"
        ],
        [
         "78",
         "27-03-2025 MAHAL "
        ],
        [
         "79",
         "26-03-2025 MAHAL"
        ],
        [
         "84",
         "26-03-2025 DHARAMPETH"
        ],
        [
         "88",
         "25-03-2025 DHARAMPETH"
        ],
        [
         "93",
         "25-03-2025 MAHAL"
        ],
        [
         "94",
         "24-03-2025 MAHAL"
        ],
        [
         "99",
         "24-03-2025 DHARAMPETH"
        ],
        [
         "104",
         "23-03-2025 MAHAL 2"
        ],
        [
         "105",
         "23-03-2025 DHARAMPETH 2"
        ],
        [
         "108",
         "23-03-2025 DHARAMPETH"
        ],
        [
         "109",
         "23-03-2025 MAHAL"
        ],
        [
         "116",
         "21-03-2025 DHARAMPETH"
        ],
        [
         "117",
         "21-03-2025 MAHAL"
        ],
        [
         "120",
         "18-03-2025 MAHAL"
        ],
        [
         "122",
         "18-03-2025 DHARAMPETH"
        ],
        [
         "128",
         "17-03-2025 DHARAMPETH"
        ],
        [
         "132",
         "17-03-2025 MAHAL"
        ],
        [
         "135",
         "16-03-2025 MAHAL"
        ],
        [
         "139",
         "16-03-2025 DHARAMPETH"
        ],
        [
         "140",
         "14-03-2025  DHARAMPETH"
        ],
        [
         "145",
         "14-03-2025 MAHAL"
        ],
        [
         "146",
         "13-03-2025 MAHAL"
        ],
        [
         "148",
         "13-02-2025 DHARAMPETH"
        ],
        [
         "155",
         "12-03-2025 DHARAMPETH"
        ],
        [
         "159",
         "11-03-2025 DHARAMPETH"
        ],
        [
         "162",
         "11-03-2025 MAHAL"
        ],
        [
         "163",
         "10-03-2025 MAHAL"
        ],
        [
         "167",
         "10-03-2025 DHARMPETH"
        ],
        [
         "169",
         "09-03-2025 DHARAMPETH"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 112
       }
      },
      "text/plain": [
       "3       08-04-2025 DHARAMPETH\n",
       "4            08-04-2025 MAHAL\n",
       "9       07-04-2025 DHARAMPETH\n",
       "10           07-04-2025 MAHAL\n",
       "20           06-04-2025 MAHAL\n",
       "                ...          \n",
       "342          04-02-2025 MAHAL\n",
       "348      03-02-2025 DHARMPETH\n",
       "352      01-02-2025 DHARMPETH\n",
       "361    31-01-2025  DHARAMPETH\n",
       "367         30-01-2025 Dharam\n",
       "Name: loc, Length: 112, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.DataFrame(\n",
    "    {\n",
    "        \"Po\": [\n",
    "            (\n",
    "                # sheetData.iloc[:, 5][3]\n",
    "                # if str(sheetData.iloc[:, 3][3]) == \"nan\"\n",
    "                # else\n",
    "                sheetData.iloc[:, 3][3]\n",
    "            )\n",
    "            for sheetData in excelBooks[\"Swiggy\"][0].values()\n",
    "        ],\n",
    "        \"loc\": [(sheetName) for sheetName in excelBooks[\"Swiggy\"][0].keys()],\n",
    "    }\n",
    ")\n",
    "ser[ser[\"Po\"].apply(lambda po: str(po) == \"nan\")][\"loc\"]\n",
    "# ser.apply(lambda row: row[\"loc\"] if str(row[\"Po\"]) == \"nan\" else row[\"Po\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96d462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "loc",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "da9f0b76-3aa4-4ed5-8cb4-18f78366a895",
       "rows": [
        [
         "Shipping Address :-Gadewar Lawns Plot No.31,32,33,36,37And 38,K. H. No, 72/2, Situated At Gadewar Lawn , Shri Ram Wadi",
         "905"
        ],
        [
         "Shipping Address :-Ground floor \"Jayanti Mansion III\"Manish nagar  Nagpur Maharashtra",
         "11092"
        ],
        [
         "Shipping Address :-Khasra No 18/2, city Survey No.718, House No. 781/B, Situated at Village Ajni,       ",
         "11512"
        ],
        [
         "Shipping Address :-Plot No. 151, CTS No. 135Puja Sabhagrah , Ravi Nagar Square, Ram Nagar",
         "11664"
        ],
        [
         "Shipping Address :-Unit no - G-1, Plot no.58 ,sardar patel timber Dhantoli , NAGPUR- 440027",
         "11231"
        ],
        [
         "Shipping Address :-Unit nos - 59 to 71 Lower Ground FloorGinger Square\" City Survey No - 1049",
         "12421"
        ],
        [
         "Shipping Address :-Vinayak Tower\" , Lower Ground Floor, Survey No.212 Gurudev Nagar Main Road , New Nanadanvan , ",
         "11300"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7
       }
      },
      "text/plain": [
       "loc\n",
       "Shipping Address :-Gadewar Lawns Plot No.31,32,33,36,37And 38,K. H. No, 72/2, Situated At Gadewar Lawn , Shri Ram Wadi      905\n",
       "Shipping Address :-Ground floor \"Jayanti Mansion III\"Manish nagar  Nagpur Maharashtra                                     11092\n",
       "Shipping Address :-Khasra No 18/2, city Survey No.718, House No. 781/B, Situated at Village Ajni,                         11512\n",
       "Shipping Address :-Plot No. 151, CTS No. 135Puja Sabhagrah , Ravi Nagar Square, Ram Nagar                                 11664\n",
       "Shipping Address :-Unit no - G-1, Plot no.58 ,sardar patel timber Dhantoli , NAGPUR- 440027                               11231\n",
       "Shipping Address :-Unit nos - 59 to 71 Lower Ground FloorGinger Square\" City Survey No - 1049                             12421\n",
       "Shipping Address :-Vinayak Tower\" , Lower Ground Floor, Survey No.212 Gurudev Nagar Main Road , New Nanadanvan ,          11300\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"loc\": [\n",
    "            \"\".join(x.iloc[:, 0][1:4]) for x in list(excelBooks[\"Swiggy\"][0].values())\n",
    "        ],\n",
    "        \"add\": list(excelBooks[\"Swiggy\"][0].keys()),\n",
    "        \"count\": [x for x in range(len(excelBooks[\"Swiggy\"][0].keys()))],\n",
    "    }\n",
    ")\n",
    "\n",
    "df.groupby(\"loc\")[\"count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a3176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Article Code', 'Item Description', 'UoM', 'Dispatched Qty', 'Rate',\n",
       "       'Total Amount', 'Date', 'Location', 'Invoice Version', 'Retailer',\n",
       "       'Vendor Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractedDomains[\"Swiggy\"].processedDataFrame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle\n",
    "from reportlab.lib import colors\n",
    "\n",
    "\n",
    "def create_styled_table_pdf(filename):\n",
    "    doc = SimpleDocTemplate(filename, pagesize=letter)\n",
    "    elements = []\n",
    "    data = [\n",
    "        [\"Header 1\", \"Header 2\", \"Header 3\"],\n",
    "        [\"Row 1, Col 1\", \"Row 1, Col 2\", \"Row 1, Col 3\"],\n",
    "        [\"Row 2, Col 1\", \"Row 2, Col 2\", \"Row 2, Col 3\"],\n",
    "    ]\n",
    "    table = Table(data)\n",
    "    style = TableStyle(\n",
    "        [\n",
    "            (\"BACKGROUND\", (0, 0), (-1, 0), colors.grey),\n",
    "            (\"TEXTCOLOR\", (0, 0), (-1, 0), colors.whitesmoke),\n",
    "            (\"ALIGN\", (0, 0), (-1, -1), \"CENTER\"),\n",
    "            (\"FONTNAME\", (0, 0), (-1, 0), \"Helvetica-Bold\"),\n",
    "            (\"BOTTOMPADDING\", (0, 0), (-1, 0), 12),\n",
    "            (\"BACKGROUND\", (0, 1), (-1, -1), colors.beige),\n",
    "            (\"GRID\", (0, 0), (-1, -1), 1, colors.black),\n",
    "        ]\n",
    "    )\n",
    "    table.setStyle(style)\n",
    "    elements.append(table)\n",
    "    doc.build(elements)\n",
    "\n",
    "\n",
    "create_styled_table_pdf(\"styled_table_report.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624a715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SWINSTA ENT. PRIVATE LIMITATE",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "12822dd6-0a28-4f31-8ff0-b6428bcd2622",
       "rows": [
        [
         "1",
         "Shipping Address :-"
        ],
        [
         "2",
         "Vinayak Tower\" , Lower Ground Floor, Survey No.212 "
        ],
        [
         "3",
         "Gurudev Nagar Main Road , New Nanadanvan , "
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "1                                  Shipping Address :-\n",
       "2    Vinayak Tower\" , Lower Ground Floor, Survey No...\n",
       "3          Gurudev Nagar Main Road , New Nanadanvan , \n",
       "Name: SWINSTA ENT. PRIVATE LIMITATE, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(excelBooks[\"Swiggy\"][0].values())[0].iloc[:, 0][1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"Nandanvan\": ,\n",
    "    \n",
    "\t\"Byramji\": ,\n",
    "    \n",
    "\t\"Dharampeth\": ,\n",
    "    \"Mahal\": ,\n",
    "    \"Ayodha Nagar\": ,\n",
    "    \"Sai Mandir\": ,\n",
    "    \"Manish Nagar\": ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ffe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheetName, sheetData in df.items():\n",
    "    if (\n",
    "        \"RAJIDI RETAILS PRIVATE LIMITED\" not in sheetData.columns\n",
    "        and \"SWINSTA ENT. PRIVATE LIMITATE\" not in sheetData.columns\n",
    "    ):\n",
    "        print(sheetName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
